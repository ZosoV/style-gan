{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"paper_notes.ipynb","provenance":[],"authorship_tag":"ABX9TyMCr3Z6Ma3yjGoSYJnUOgac"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eTTMZzCqKbh7"},"source":["# Paper Notes\n","\n","This notebook summarizes some important question to embedding an image into the laten space of StyleGAN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Swb-gCMIRJar","executionInfo":{"status":"ok","timestamp":1621267772753,"user_tz":300,"elapsed":38177,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"c436187e-6f63-46c9-da71-6a01ce3f346b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68SGeWRERJas","executionInfo":{"status":"ok","timestamp":1621267772754,"user_tz":300,"elapsed":37979,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"406c8fbf-f260-4313-f7be-6792e401cda6"},"source":["%cd /content/gdrive/MyDrive/internship/style-gan/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/internship/style-gan\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ywIThr0nS93I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621267791588,"user_tz":300,"elapsed":56801,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"72797f59-7ef2-41a4-91cf-75c00dbdf697"},"source":["!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n","!pip install lpips\n","!pip install pytorch-ignite\n","!pip install pytorch-msssim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (8.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Collecting pyspng\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/b2/c18f96ccc62153631fdb3122cb1e13fa0c89303f4e64388a49a04bfad9f2/pyspng-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 4.2MB/s \n","\u001b[?25hCollecting ninja\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n","\u001b[K     |████████████████████████████████| 112kB 24.1MB/s \n","\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/0f/4b49476d185a273163fa648eaf1e7d4190661d1bbf37ec2975b84df9de02/imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9MB)\n","\u001b[K     |████████████████████████████████| 26.9MB 109kB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng) (1.19.5)\n","Installing collected packages: pyspng, ninja, imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.4.3 ninja-1.10.0.post2 pyspng-0.1.0\n","Collecting lpips\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/de/774d9cdb601bb938b6a501f1aeaa64288a763ebbafbeef227a3da86150d9/lpips-0.1.3-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n","\u001b[?25hInstalling collected packages: lpips\n","Successfully installed lpips-0.1.3\n","Collecting pytorch-ignite\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d3/640f70d69393b415e6a29b27c735047ad86267921ad62682d1d756556d48/pytorch_ignite-0.4.4-py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.4\n","Collecting pytorch-msssim\n","  Downloading https://files.pythonhosted.org/packages/9d/d3/3cb0f397232cf79e1762323c3a8862e39ad53eca0bb5f6be9ccc8e7c070e/pytorch_msssim-0.2.1-py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (3.7.4.3)\n","Installing collected packages: pytorch-msssim\n","Successfully installed pytorch-msssim-0.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LyKfSa-PRagO"},"source":["# Import the needed libraries\n","import matplotlib.pyplot as plt\n","import pickle\n","import torch\n","import torch.nn as nn\n","import os\n","import IPython\n","from PIL import Image\n","import glob\n","from sklearn.decomposition import PCA\n","import numpy as np \n","from torchvision.utils import save_image\n","from torchsummary import summary\n","from torchvision import models, transforms\n","from ignite.metrics import PSNR\n","from ignite.engine import Engine\n","from pytorch_msssim import ssim\n","\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import lpips\n","import warnings\n","import dnnlib\n","import pandas as pd\n","import PIL\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzCeXwiIRhUv"},"source":["# Setting global attributes\n","RESOLUTION = 1024\n","#DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","ITERATIONS = 1300\n","SAVE_STEP = 100\n","\n","# OPTIMIZER\n","LEARNING_RATE = 0.01\n","BETA_1 = 0.9\n","BETA_2 = 0.999\n","EPSILON = 1e-8\n","regularizer_lambda = 0.001\n","\n","# IMAGE TO EMBED\n","#PATH_IMAGE = \"stuff/data/expression02.png\"\n","PATH_DIR = \"stuff/data/input/\"\n","SAVING_DIR = 'stuff/results/paper_notes/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWrFpmIEaufY","executionInfo":{"status":"ok","timestamp":1620873167830,"user_tz":300,"elapsed":24194,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"765cd25c-8254-43c8-8cdc-f29b1dee665c"},"source":["DEVICE"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"nBTWRY4KSGKc"},"source":["## Loadding Pretrained Model\n","Load the pretrained model using the pickle file. I need the libraries `dnnlib` and `torch_utils` to load this model.\n","\n","It does not need source code for the networks themselves — their class definitions are loaded from the pickle via `torch_utils.persistence`.\n"]},{"cell_type":"code","metadata":{"id":"RuaFXFXRSGsH"},"source":["PRETRAINED_MODEL = \"stuff/pretrained_models/ffhq.pkl\"\n","\n","with open(PRETRAINED_MODEL, 'rb') as f:\n","    G = pickle.load(f)['G_ema'].to(DEVICE)  # torch.nn.Module-\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OB4B7-qtRrA_"},"source":["The pickle contains three networks. `'G'` and `'D'` are instantaneous snapshots taken during training, and `'G_ema'` represents a moving average of the generator weights over several training steps. The networks are regular instances of `torch.nn.Module`, with all of their parameters and buffers placed on the CPU at import and gradient computation disabled by default.\n","\n","The generator consists of two submodules, `G.mapping` and `G.synthesis`, that can be executed separately. They also support various additional options:\n","\n","```.python\n","w = G.mapping(z, c, truncation_psi=0.5, truncation_cutoff=8)\n","img = G.synthesis(w, noise_mode='const', force_fp32=True)\n","```\n","where\n","\n","```.python\n","z: latent_code\n","c: class label\n","w: intermediate latent_code\n","```\n","\n","Please refer to [`generate.py`](./generate.py), [`style_mixing.py`](https://github.com/NVlabs/stylegan2-ada-pytorch/blob/main/style_mixing.py), and [`projector.py`](./projector.py) for further examples.\n","\n","From G we need to extract the `mapping` and the `synthesis` modules."]},{"cell_type":"markdown","metadata":{"id":"X4bkts54KtHs"},"source":["## Sampling\n"]},{"cell_type":"markdown","metadata":{"id":"36uJiYZ1Kv0D"},"source":["1. Sample (generate) 50 face images (in z-space) using StyleGAN and look at them carefully. What artifacts can you observe? How could you tell an StyleGAN image apart from a real image?"]},{"cell_type":"code","metadata":{"id":"_GcBHsrTTxvE"},"source":["z_latents = torch.randn([50, G.z_dim]).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPXgjsDQKu_i"},"source":["truncation_value = 1\n","output_dir = os.path.join(SAVING_DIR,f'/trunc_{truncation_value}')\n","if not os.path.exits(output_dir):\n","  os.makedir(output_dir)\n","\n","for latent_idx, z in enumerate(z_latents):\n","    print('Generating image for latent (%d/%d) ...' % (latent_idx, len(z_latents)))\n","    img = G(z.unsqueeze(0), None, truncation_psi=truncation_value, noise_mode='const')\n","    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n","    filename = os.path.join(output_dir, f'image_{latent_idx:03d}.png')\n","    PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lvaL1kBROEM"},"source":["2. Sample 50 images without truncation (truncation factor t = 1), 50 images with truncation factor t = 0.7, and to images with truncation factor t = 0.5. What do you observe? Can you verbally describe the differences between the different truncation factors (the truncation factor has another name in the paper, not t)."]},{"cell_type":"code","metadata":{"id":"bnLWkwcMRU9T"},"source":["truncation_value = 0.7\n","output_dir = os.path.join(SAVING_DIR,f'/trunc_{truncation_value}')\n","if not os.path.exits(output_dir):\n","  os.makedir(output_dir)\n","\n","for latent_idx, z in enumerate(z_latents):\n","    print('Generating image for latent (%d/%d) ...' % (latent_idx, len(z_latents)))\n","    img = G(z.unsqueeze(0), None, truncation_psi=truncation_value, noise_mode='const')\n","    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n","    filename = os.path.join(output_dir, f'image_{latent_idx:03d}.png')\n","    PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DuID-cA_URLu"},"source":["truncation_value = 0.5\n","output_dir = os.path.join(SAVING_DIR,f'/trunc_{truncation_value}')\n","if not os.path.exits(output_dir):\n","  os.makedir(output_dir)\n","\n","for latent_idx, z in enumerate(z_latents):\n","    print('Generating image for latent (%d/%d) ...' % (latent_idx, len(z_latents)))\n","    img = G(z.unsqueeze(0), None, truncation_psi=truncation_value, noise_mode='const')\n","    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n","    filename = os.path.join(output_dir, f'image_{latent_idx:03d}.png')\n","    PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lMF6GZAiVNXe"},"source":["3. What is the difference between w / w+ or z / z+ space? In w there is only one latent code with 512 floating point variables and in w+ there are 18 latent codes with 512 floating point variables. There are also different spaces like w2, w3, w6, w9. In these other spaces the latent codes are split into groups that can be different. For example, in w2 there are two groups of latent codes (one for the first 9 layers and one for the later 9 layers). Sample k images from z, z2, z3, z6, z9, z18 = z+. What do you observe? Which images look realistic and which do not look realistic?"]}]}