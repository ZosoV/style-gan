{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"metrics.ipynb","provenance":[],"authorship_tag":"ABX9TyOt5MzhnQeBG18Dz7aymyke"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ATEtAj_vGD1J"},"source":["# Checking Quantitative Metrics\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Swb-gCMIRJar","executionInfo":{"status":"ok","timestamp":1621278151887,"user_tz":300,"elapsed":1494,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"9ce92964-fa2e-436a-ead1-52a2a7352004"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68SGeWRERJas","executionInfo":{"status":"ok","timestamp":1621278151888,"user_tz":300,"elapsed":1468,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"d63e6cd4-a04d-4551-e0ef-351a3a0fa595"},"source":["%cd /content/gdrive/MyDrive/internship/style-gan/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/internship/style-gan\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ywIThr0nS93I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621278164161,"user_tz":300,"elapsed":13720,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}},"outputId":"9366505b-1b5a-46a5-f864-8b2465ad134f"},"source":["!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n","!pip install lpips\n","!pip install pytorch-ignite\n","!pip install pytorch-msssim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (8.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Requirement already satisfied: pyspng in /usr/local/lib/python3.7/dist-packages (0.1.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.0.post2)\n","Requirement already satisfied: imageio-ffmpeg==0.4.3 in /usr/local/lib/python3.7/dist-packages (0.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng) (1.19.5)\n","Requirement already satisfied: lpips in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.4)\n","Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n","Requirement already satisfied: pytorch-msssim in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zo6vptIbpnUr","executionInfo":{"status":"ok","timestamp":1621965207272,"user_tz":300,"elapsed":9,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGMhFTzBxp7HVTzAiM2RVp2Yr4OebxgYoOPMyr=s64","userId":"16556328622175901106"}}},"source":["SAVING_DIR = 'stuff/results/metrics/'\n","PATH_DIR = \"stuff/data/input/\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZhPRqfhGD1N","executionInfo":{"elapsed":2032,"status":"ok","timestamp":1620104360454,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"b313085a-0228-469f-a5ad-c4a769201bba"},"source":["!ls $SAVING_DIR/images/no_square_regularizer_lambda_0-001/last_generated"],"execution_count":null,"outputs":[{"output_type":"stream","text":["aatik-tasneem-7omHUGhhmZ0-unsplash_latents_iters_001300_step_0100_w_mean.png\n","aiony-haust-3TLl_97HNJo-unsplash_latents_iters_001300_step_0100_w_mean.png\n","aleksandr-minakov-xDyqR14KyAs-unsplash_latents_iters_001300_step_0100_w_mean.png\n","alex-lee-l7oI8wCfQ8Y-unsplash_latents_iters_001300_step_0100_w_mean.png\n","amin-rk-QKxRH1sAfYY-unsplash_latents_iters_001300_step_0100_w_mean.png\n","andrew-heald-z2wyh1Maq8E-unsplash_latents_iters_001300_step_0100_w_mean.png\n","annie-spratt-ZyWN6N41JUc-unsplash_latents_iters_001300_step_0100_w_mean.png\n","austin-wade-X6Uj51n5CE8-unsplash_latents_iters_001300_step_0100_w_mean.png\n","awab-husameldin-678MnkzVdRU-unsplash_latents_iters_001300_step_0100_w_mean.png\n","ayo-ogunseinde-sibVwORYqs0-unsplash_latents_iters_001300_step_0100_w_mean.png\n","dorrell-tibbs-gisFZKWpKQ4-unsplash_latents_iters_001300_step_0100_w_mean.png\n","pexels-wallace-chuck-4580470_latents_iters_001300_step_0100_w_mean.png\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rzLNOZgxGD1O"},"source":["## Reconstruction Metrics\n","\n","### Peak signal-to-noise ratio (PSNR)\n","\n","PSNR is most easily defined via the mean squared error (MSE). Given a noise-free $m\\times n$ monochrome image $I$ and its noisy approximation $K$, MSE is defined as:\n","\n","$$M S E=\\frac{1}{m n} \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1}[I(i, j)-K(i, j)]^{2} $$\n","\n","\n","The PSNR is defined as:\n","\n","$$\n","\\begin{aligned}\n","P S N R &=10 \\cdot \\log _{10}\\left(\\frac{M A X_{I}^{2}}{M S E}\\right) \\\\\n","&=20 \\cdot \\log _{10}\\left(\\frac{M A X_{I}}{\\sqrt{M S E}}\\right) \\\\\n","&=20 \\cdot \\log _{10}\\left(M A X_{I}\\right)-10 \\cdot \\log _{10}(M S E)\n","\\end{aligned}\n","$$\n","\n","Here, $MAX_I$ is the maximum possible pixel value of the image.\n"]},{"cell_type":"code","metadata":{"id":"w9bBd51oGD1P","cellView":"form"},"source":["#@title build_tensor_results \n","#@markdown Load the generated imgs with its respective reference img\n","def build_tensor_results(path_generated_imgs, path_references):\n","  input_data = load_data(path_references)\n","\n","  generated_imgs = load_data(path_generated_imgs)\n","\n","  full_batches = []\n","\n","  for i in range(12):\n","    references = input_data[i]['img']\n","    synthetics = generated_imgs[i]['img']\n","\n","    batch_data = np.stack([synthetics, references], axis = 0)\n","\n","    full_batches.append(batch_data)\n","\n","  full_batches = np.array(full_batches)\n","  print(\"full_batches numpy: \", full_batches.shape)\n","\n","  # convert to pytorch tensor\n","  full_batches = torch.tensor(full_batches, device = DEVICE, dtype = torch.float32)\n","  full_batches = full_batches.permute(0, 1, 4, 2, 3)\n","  print(\"full_batches tensor: \", full_batches.size())\n","\n","  return full_batches"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9ROxLS8GD1P","executionInfo":{"elapsed":13150,"status":"ok","timestamp":1620104371600,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"fd7c441b-dd6f-45cb-9882-540cfb5e6a67"},"source":["path_generated_imgs = os.path.join(SAVING_DIR,\"images/no_square_regularizer_lambda_0-001/last_generated/\")\n","\n","full_batches = build_tensor_results(path_generated_imgs)\n","full_batches.size()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["full_batches numpy:  (12, 2, 1024, 1024, 3)\n","full_batches tensor:  torch.Size([12, 2, 3, 1024, 1024])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 2, 3, 1024, 1024])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"6kwUfo8qGD1P"},"source":["def get_PSNR(full_batches):\n","  def process_function(engine, batch):\n","      y_pred = batch[0]\n","      y = batch[1]\n","      return y_pred, y\n","\n","  engine = Engine(process_function)\n","  psnr = PSNR(data_range=255.0)\n","  psnr.attach(engine, \"psnr\")\n","\n","  state = engine.run(full_batches)\n","  print(f\"n_imgs: {full_batches.size(0)} PSNR: {state.metrics['psnr']}\")\n","\n","  return state.metrics['psnr']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-ZWuZy4GD1Q","executionInfo":{"elapsed":13123,"status":"ok","timestamp":1620104371602,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"65d08989-6ea6-4fe2-aea7-f3c376fcf477"},"source":["psnr_metric = get_PSNR(full_batches)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["n_imgs: 12 PSNR: 23.279572988230957\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lXS8f1RgGD1Q"},"source":["## Root Mean Square Deviation (RMSD)\n","\n","Given two $m\\times n$ images $I_1$ and $I_2$\n","\n","$$M S E=\\frac{1}{m n} \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1}[I_1(i, j)-I_2(i, j)]^{2} $$\n","\n","Then, RMSD is\n","\n","$$\n","\\mathrm{RMSD}=\\sqrt{MSE}\n","$$"]},{"cell_type":"code","metadata":{"id":"vD_gW_-pGD1Q"},"source":["def get_RMSD(full_batches):\n","  generates = full_batches[:,0,:,:,:] / 255.0\n","  references = full_batches[:,1,:,:,:] / 255.0\n","\n","  criterion = nn.MSELoss()\n","  rmsd = torch.sqrt(criterion(generates, references))\n","\n","  print(f\"n_imgs: {full_batches.size(0)} RMSD: {rmsd}\")\n","  return rmsd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qelv5i4tGD1R","executionInfo":{"elapsed":13100,"status":"ok","timestamp":1620104371603,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"9707270d-0b15-4991-d3c6-4489e3703c0a"},"source":["get_RMSD(full_batches)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["n_imgs: 12 RMSD: 0.07621462643146515\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(0.0762, device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"waNOwZ8CGD1R"},"source":["## VGG perceptual similarity"]},{"cell_type":"code","metadata":{"cellView":"form","id":"KyRWgasWGD1S"},"source":["#@title the VGG16 Perceptual Network\n","\n","class PerceptualVGG16(torch.nn.Module):\n","    def __init__(self, requires_grad=False, n_layers=[2, 4, 14, 21]):\n","        super(PerceptualVGG16, self).__init__()\n","        \n","        # Dowsampling according to input of ImageNet 256x256\n","        self.upsample2d = torch.nn.Upsample(scale_factor=256/RESOLUTION, mode='bicubic')\n","\n","        # Get the pretrained vgg16 model\n","        vgg_pretrained_features = models.vgg16(pretrained=True).features\n","\n","        self.slice0 = torch.nn.Sequential()\n","        self.slice1 = torch.nn.Sequential()\n","        self.slice2 = torch.nn.Sequential()\n","        self.slice3 = torch.nn.Sequential()\n","        \n","        # [0,1] layers indexes\n","        for x in range(n_layers[0]):  \n","            self.slice0.add_module(str(x), vgg_pretrained_features[x])\n","            \n","        # [2, 3] layers indexes\n","        for x in range(n_layers[0], n_layers[1]):  # relu1_2\n","            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n","        \n","        # [4, 13] layers indexes\n","        for x in range(n_layers[1], n_layers[2]): # relu3_2\n","            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n","\n","        # [14, 20] layers indexes\n","        for x in range(n_layers[2], n_layers[3]):# relu4_2\n","            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n","\n","        # Setting the gradients to false\n","        if not requires_grad:\n","            for param in self.parameters():\n","                param.requires_grad=False\n","                \n","    def forward(self, x):\n","        upsample = self.upsample2d(x)\n","        \n","        h0 = self.slice0(upsample)\n","        h1 = self.slice1(h0)\n","        h2 = self.slice2(h1)\n","        h3 = self.slice3(h2)\n","\n","        return h0, h1, h2, h3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"nBPbrikTGD1V"},"source":["#@title Pass VGG network\n","def get_vgg_perceptual(full_batches, separate = True):\n","\n","  generates = full_batches[:,0,:,:,:].clone() / 255.0\n","  references = full_batches[:,1,:,:,:].clone() / 255.0\n","\n","  # normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","  #                                std=[0.229, 0.224, 0.225])\n","  # generates = normalize(generates)\n","  # references = normalize(references)\n","\n","  perceptual_net = PerceptualVGG16(n_layers=[2,4,14,21]).to(DEVICE)\n","\n","  def get_loss(synth_img, original_img):\n","    real_0,real_1,real_2,real_3 = perceptual_net(original_img)\n","    synth_0,synth_1,synth_2,synth_3 = perceptual_net(synth_img)\n","\n","    perceptual_loss=0\n","    perceptual_loss+=MSE_Loss(synth_0,real_0)\n","    perceptual_loss+=MSE_Loss(synth_1,real_1)\n","    perceptual_loss+=MSE_Loss(synth_2,real_2)\n","    perceptual_loss+=MSE_Loss(synth_3,real_3)\n","\n","    return perceptual_loss\n","\n","  if separate:\n","    perceptual_per_img = []\n","\n","    for i in range(full_batches.size(0)):\n","      \n","      perceptual_loss = get_loss(generates[i].unsqueeze(0), references[i].unsqueeze(0))\n","\n","      perceptual_per_img.append(perceptual_loss.item())\n","\n","    metric = np.mean(perceptual_per_img)\n","  else:\n","\n","    metric = get_loss(generates, references)\n","\n","  print(f\"n_imgs: {full_batches.size(0)} VGG: {metric}\")\n","\n","  return metric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9JvVKWdNVVN"},"source":["def get_VGG(full_batches, separate = True):\n","  url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n","  with dnnlib.util.open_url(url) as f:\n","      perceptual_vgg16 = torch.jit.load(f).eval().to(DEVICE)\n","\n","  generates = full_batches[:,0,:,:,:].clone()\n","  references = full_batches[:,1,:,:,:].clone()\n","\n","  # generates = F.interpolate(generates, size=(256, 256), mode='area')\n","  # references = F.interpolate(references, size=(256, 256), mode='area')\n","  \n","  perceptual_per_img = []\n","  \n","  if separate:\n","    for i in range(full_batches.size(0)):\n","\n","      synth_features = perceptual_vgg16(generates[i].unsqueeze(0), resize_images=True, return_lpips=False)\n","      reference_features = perceptual_vgg16(references[i].unsqueeze(0), resize_images=True, return_lpips=False)\n","\n","      perceptual_loss = (reference_features - synth_features).square().sum()\n","\n","      perceptual_per_img.append(perceptual_loss.item())\n","\n","    metric = np.mean(perceptual_per_img)\n","  else:\n","    synth_features = perceptual_vgg16(generates, resize_images=True, return_lpips=False)\n","    reference_features = perceptual_vgg16(references, resize_images=True, return_lpips=False)\n","\n","    metric = (reference_features - synth_features).square().sum()\n","\n","  print(f\"n_imgs: {full_batches.size(0)} VGG: {metric}\")\n","\n","  return metric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSVFOfNkGD1V","executionInfo":{"elapsed":19529,"status":"ok","timestamp":1620104378071,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"2aeecaef-aa84-4ecb-abb5-f076e16a1118"},"source":["get_VGG(full_batches, separate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt ... done\n","n_imgs: 12 VGG: 0.46020272374153137\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(0.4602, device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"PzhjgAcQGD1W"},"source":["## LPIPS Perceptual Metric"]},{"cell_type":"code","metadata":{"id":"GaPzzewwGD1W"},"source":["def get_LPIPS(full_batches, separate = True):\n","  url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n","  with dnnlib.util.open_url(url) as f:\n","      perceptual_vgg16 = torch.jit.load(f).eval().to(DEVICE)\n","\n","  generates = full_batches[:,0,:,:,:].clone()\n","  references = full_batches[:,1,:,:,:].clone()\n","\n","  generates = F.interpolate(generates, size=(256, 256), mode='area')\n","  references = F.interpolate(references, size=(256, 256), mode='area')\n","  \n","  perceptual_per_img = []\n","  \n","  if separate:\n","    for i in range(full_batches.size(0)):\n","\n","      synth_features = perceptual_vgg16(generates[i].unsqueeze(0), resize_images=False, return_lpips=True)\n","      reference_features = perceptual_vgg16(references[i].unsqueeze(0), resize_images=False, return_lpips=True)\n","\n","      perceptual_loss = (reference_features - synth_features).square().sum()\n","\n","      perceptual_per_img.append(perceptual_loss.item())\n","\n","    metric = np.mean(perceptual_per_img)\n","  else:\n","    synth_features = perceptual_vgg16(generates, resize_images=False, return_lpips=True)\n","    reference_features = perceptual_vgg16(references, resize_images=False, return_lpips=True)\n","\n","    metric = (reference_features - synth_features).square().sum()\n","\n","  print(f\"n_imgs: {full_batches.size(0)} LPIPS: {metric}\")\n","\n","  return metric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rKwrFL9GD1W","executionInfo":{"elapsed":20517,"status":"ok","timestamp":1620104379082,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"d1a77e0c-b467-4aeb-f449-5b4fc277e05e"},"source":["get_LPIPS(full_batches)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["n_imgs: 12 LPIPS: 0.11547330704828103\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.11547330704828103"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"8bmJ1LVSGD1W"},"source":["## Differentiable structural similarity (SSIM) index."]},{"cell_type":"code","metadata":{"id":"jmXUTgeLGD1X"},"source":["def get_SSIM(full_batches):\n","  generates = full_batches[:,0,:,:,:]\n","  references = full_batches[:,1,:,:,:]\n","\n","  metric = ssim(generates, references,data_range=255.0)\n","\n","  print(f\"n_imgs: {full_batches.size(0)} SSIM: {metric}\")\n","\n","  return metric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jddu7HHzGD1X","executionInfo":{"elapsed":20495,"status":"ok","timestamp":1620104379084,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"638183b4-b1e7-4182-fc3d-14f028b8ef3a"},"source":["get_SSIM(full_batches)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["n_imgs: 12 SSIM: 0.705211877822876\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(0.7052, device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"CqQ5Xty5FpHS"},"source":["### Get the metrics of different executions"]},{"cell_type":"code","metadata":{"id":"cTxAHMA6F5Zc"},"source":["folders_results = {\n","    \"no square lambda: 0.001\" : \"images/no_square_regularizer_lambda_0-001/last_generated/\",\n","    \"bicubic lambda: 0.001\" :\"images/lambda_0-001_bicubic/last_generated/\",\n","    \"area lambda: 0.001\" :\"images/lambda_0-001_area/last_generated/\",\n","    \"area lambda: 0.005\" :\"images/lambda_0-005_area/last_generated/\",\n","    \"area lambda: 0.01\" :\"images/lambda_0-01_area/last_generated/\",\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNcIp0z-QiAj"},"source":["df = pd.DataFrame(columns=[\"SSIM\", \"RMSE\", \"PSNR\", \"VGG\", \"LPIPS\"], index= [ k for k, v in folders_results.items()])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":976},"id":"EqTU3bNxGD1Y","executionInfo":{"elapsed":15990,"status":"ok","timestamp":1620104672530,"user":{"displayName":"Oscar Guarnizo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEU_2_wHtuPauwN5OqjSzW2w3Grhz9rxc4iuVe=s64","userId":"13660462714184344714"},"user_tz":300},"outputId":"c69b937e-1773-47bb-b1a1-813dc71ce011"},"source":["df = pd.DataFrame(columns=[\"SSIM\", \"RMSE\", \"PSNR\", \"VGG\", \"LPIPS\"],\n","                  index= [ k for k, v in folders_results.items()])\n","\n","for k, path in folders_results.items():\n","  full_batches = build_tensor_results(path)\n","  print(path)\n","  print(full_batches.size())\n","\n","  metric_ssim = get_SSIM(full_batches).item()\n","  metric_rmse = get_RMSD(full_batches).item()\n","  metric_psnr = get_PSNR(full_batches)\n","  metric_vgg = get_VGG(full_batches,separate=False).item()\n","  metric_lpips = get_LPIPS(full_batches)\n","\n","  df.loc[k] = [\n","      metric_ssim, \n","      metric_rmse,\n","      metric_psnr, \n","      metric_vgg,\n","      metric_lpips]\n","\n","df"],"execution_count":null,"outputs":[{"output_type":"stream","text":["full_batches numpy:  (12, 2, 1024, 1024, 3)\n","full_batches tensor:  torch.Size([12, 2, 3, 1024, 1024])\n","images/no_square_regularizer_lambda_0-001/last_generated/\n","torch.Size([12, 2, 3, 1024, 1024])\n","n_imgs: 12 SSIM: 0.705211877822876\n","n_imgs: 12 RMSD: 0.07621462643146515\n","n_imgs: 12 PSNR: 23.279572988230957\n","n_imgs: 12 VGG: 0.46020272374153137\n","n_imgs: 12 LPIPS: 0.11547330704828103\n","full_batches numpy:  (12, 2, 1024, 1024, 3)\n","full_batches tensor:  torch.Size([12, 2, 3, 1024, 1024])\n","images/lambda_0-001_bicubic/last_generated/\n","torch.Size([12, 2, 3, 1024, 1024])\n","n_imgs: 12 SSIM: 0.6869617700576782\n","n_imgs: 12 RMSD: 0.08984023332595825\n","n_imgs: 12 PSNR: 21.962373764348147\n","n_imgs: 12 VGG: 0.835750162601471\n","n_imgs: 12 LPIPS: 0.16997494486471018\n","full_batches numpy:  (12, 2, 1024, 1024, 3)\n","full_batches tensor:  torch.Size([12, 2, 3, 1024, 1024])\n","images/lambda_0-001_area/last_generated/\n","torch.Size([12, 2, 3, 1024, 1024])\n","n_imgs: 12 SSIM: 0.7014564871788025\n","n_imgs: 12 RMSD: 0.07909423112869263\n","n_imgs: 12 PSNR: 22.998625816770627\n","n_imgs: 12 VGG: 0.28437340259552\n","n_imgs: 12 LPIPS: 0.12000335504611333\n","full_batches numpy:  (12, 2, 1024, 1024, 3)\n","full_batches tensor:  torch.Size([12, 2, 3, 1024, 1024])\n","images/lambda_0-005_area/last_generated/\n","torch.Size([12, 2, 3, 1024, 1024])\n","n_imgs: 12 SSIM: 0.7006847858428955\n","n_imgs: 12 RMSD: 0.08083193749189377\n","n_imgs: 12 PSNR: 22.740873743926883\n","n_imgs: 12 VGG: 0.5540578961372375\n","n_imgs: 12 LPIPS: 0.12898852986594042\n","full_batches numpy:  (12, 2, 1024, 1024, 3)\n","full_batches tensor:  torch.Size([12, 2, 3, 1024, 1024])\n","images/lambda_0-01_area/last_generated/\n","torch.Size([12, 2, 3, 1024, 1024])\n","n_imgs: 12 SSIM: 0.7025644183158875\n","n_imgs: 12 RMSD: 0.07933840155601501\n","n_imgs: 12 PSNR: 22.83764867785952\n","n_imgs: 12 VGG: 0.46856799721717834\n","n_imgs: 12 LPIPS: 0.12782603781670332\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SSIM</th>\n","      <th>RMSE</th>\n","      <th>PSNR</th>\n","      <th>VGG</th>\n","      <th>LPIPS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>no square lambda: 0.001</th>\n","      <td>0.705212</td>\n","      <td>0.0762146</td>\n","      <td>23.2796</td>\n","      <td>0.460203</td>\n","      <td>0.115473</td>\n","    </tr>\n","    <tr>\n","      <th>bicubic lambda: 0.001</th>\n","      <td>0.686962</td>\n","      <td>0.0898402</td>\n","      <td>21.9624</td>\n","      <td>0.83575</td>\n","      <td>0.169975</td>\n","    </tr>\n","    <tr>\n","      <th>area lambda: 0.001</th>\n","      <td>0.701456</td>\n","      <td>0.0790942</td>\n","      <td>22.9986</td>\n","      <td>0.284373</td>\n","      <td>0.120003</td>\n","    </tr>\n","    <tr>\n","      <th>area lambda: 0.005</th>\n","      <td>0.700685</td>\n","      <td>0.0808319</td>\n","      <td>22.7409</td>\n","      <td>0.554058</td>\n","      <td>0.128989</td>\n","    </tr>\n","    <tr>\n","      <th>area lambda: 0.01</th>\n","      <td>0.702564</td>\n","      <td>0.0793384</td>\n","      <td>22.8376</td>\n","      <td>0.468568</td>\n","      <td>0.127826</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             SSIM       RMSE     PSNR       VGG     LPIPS\n","no square lambda: 0.001  0.705212  0.0762146  23.2796  0.460203  0.115473\n","bicubic lambda: 0.001    0.686962  0.0898402  21.9624   0.83575  0.169975\n","area lambda: 0.001       0.701456  0.0790942  22.9986  0.284373  0.120003\n","area lambda: 0.005       0.700685  0.0808319  22.7409  0.554058  0.128989\n","area lambda: 0.01        0.702564  0.0793384  22.8376  0.468568  0.127826"]},"metadata":{"tags":[]},"execution_count":41}]}]}